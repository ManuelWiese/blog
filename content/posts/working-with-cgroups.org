#+title: Working with cgroups (Part 1)
#+tags[]: linux cgroups container-basics
#+date: 2025-01-01T10:16:12+01:00
#+draft: true

* Introduction to cgroups
Control Groups (cgroups) are a powerful feature of the Linux kernel that allow administrators and developers to organize processes and control their usage of system resources such as CPU, memory, and IO. Initially introduced in Linux 2.6.24, cgroups are the foundation for container technologies like Docker and Kubernetes. This article will cover the basics of working with cgroups and demonstrate how to use them to manage system resources.

* What are cgroups?
Cgroups provide a virtual file system interface for monitoring and limiting resource usage. They allow you to create hierarchies of processes, each with specific resource constraints, making them a vital tool for performance tuning, debugging, and isolating applications.

* Creating a new cgroup
To create a new cgroup, you need to create a directory in the =/sys/fs/cgroup= file system, which is mounted by the Linux kernel. When a new folder is created, it is automatically populated with various virtual files used to manage and monitor resources.

For simplicity, all commands in this article are run as root to ensure access to the required files.

#+begin_src bash
root@ganymed:~# mkdir /sys/fs/cgroup/my_cgroup
root@ganymed:~# ls -lah /sys/fs/cgroup/my_cgroup | head
insgesamt 0
drwxr-xr-x  2 root root 0 Jan  1 14:34 .
dr-xr-xr-x 13 root root 0 Jan  1 14:30 ..
-r--r--r--  1 root root 0 Jan  1 14:34 cgroup.controllers
-r--r--r--  1 root root 0 Jan  1 14:34 cgroup.events
-rw-r--r--  1 root root 0 Jan  1 14:34 cgroup.freeze
--w-------  1 root root 0 Jan  1 14:34 cgroup.kill
-rw-r--r--  1 root root 0 Jan  1 14:34 cgroup.max.depth
-rw-r--r--  1 root root 0 Jan  1 14:34 cgroup.max.descendants
-rw-r--r--  1 root root 0 Jan  1 14:34 cgroup.pressure
#+end_src

* Moving a process to a cgroup
To move a process to a cgroup, write the process ID (PID) into the =cgroup.procs= file of the desired cgroup. For instance, to move the current shell process to the =my_cgroup= cgroup:

#+begin_src bash
root@ganymed:~# echo $$ > /sys/fs/cgroup/my_cgroup/cgroup.procs
#+end_src

Afterward, all child processes of the shell will automatically belong to the same cgroup. You can verify this by checking the contents of the =cgroup.procs= file:

#+begin_src bash
root@ganymed:~# cat /sys/fs/cgroup/my_cgroup/cgroup.procs
16198
16233
#+end_src

Here, the output shows two PIDs: one for the shell process and one for the =cat= command used to display the file's contents.

* Limiting CPU usage
Cgroups allow you to control CPU usage for processes within a group. This is achieved by modifying the =cpu.max= file. Each CPU core provides 100,000 time units per second. To limit a group to 50% usage on a 4-core system, set the value to 200,000:

#+begin_src bash
root@ganymed:~# echo 200000 > /sys/fs/cgroup/my_cgroup/cpu.max
#+end_src

To test this, you can run a CPU-intensive application like =stress-ng=:

#+begin_src bash
root@ganymed:~# stress-ng --cpu 4
#+end_src

Using tools like =htop=, you can observe the CPU usage of the =stress-ng= processes and verify that it aligns with the set limit.

* Limiting Memory usage
To limit the memory usage of processes in a cgroup, you can set constraints(in bytes) using the =memory.max= file. For example, to restrict memory usage to 100MB, execute the following command:

#+begin_src bash
root@ganymed:~# echo $((100 * 1024 * 1024)) > /sys/fs/cgroup/my_cgroup/memory.max
#+end_src

Using the =memory.events= file, you can for example check the number of oom events. In the following example we check the content of =memory.events=, start a memory hog using 200Mb with =stress-ng= and check the =memory.events= file again. Since we started a process using more memory as set in =memory.max=, the number of oom events should increase.

#+begin_src bash
  root@ganymed:~# cat /sys/fs/cgroup/my_cgroup/memory.events
  low 0
  high 0
  max 530060
  oom 814
  oom_kill 741

  root@ganymed:~# stress-ng --vm 1 --vm-bytes 200M --timeout 10s
  stress-ng: info:  [50625] setting to a 10 secs run per stressor
  stress-ng: info:  [50625] dispatching hogs: 1 vm
  stress-ng: info:  [50625] skipped: 0
  stress-ng: info:  [50625] passed: 1: vm (1)
  stress-ng: info:  [50625] failed: 0
  stress-ng: info:  [50625] metrics untrustworthy: 0
  stress-ng: info:  [50625] successful run completed in 10.21 secs

  root@ganymed:~# cat /sys/fs/cgroup/my_cgroup/memory.events
  low 0
  high 0
  max 562636
  oom 862
  oom_kill 789
#+end_src

=stress-ng= does not report anything unusual here, but the processes were killed almost 50 times.

* Conclusion and next steps
This article introduced the basic concepts of cgroups and demonstrated how to create a cgroup, move processes into it, and limit their CPU and memory usage. In the next part, we will explore =cgroup-tools=, a convenient way to create cgroups and add processes to them.
